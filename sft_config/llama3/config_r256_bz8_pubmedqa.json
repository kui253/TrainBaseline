{
    "model_name_or_path": "../ckpts/meta-llama/Meta-Llama-3-8B-Instruct",
    "system_prompt": "You are a good AI assistant",
    "sft_task_ds": "pubmedqa",
    "train_file_dir": "train",
    "eval_file_dir": "validation",
    "content_field": [
        "QUESTION",
        "CONTEXTS"
    ],
    "response_field": [
        "final_decision",
        "LONG_ANSWER"
    ],
    "template_str_dir": "./formatting_template/Llama3.yaml",
    "response_template": "<|start_header_id|>assistant<|end_header_id|>\n\n",
    "human_template": "<|start_header_id|>user<|end_header_id|>\n\n",
    "run_name": "sft_llama3_pubmedqa",
    "dataset_num_proc": 32,
    "max_grad_norm": 1,
    "warmup_steps": 5,
    "learning_rate": 2e-4,
    "weight_decay": 0.01,
    "per_device_train_batch_size": 4,
    "save_total_limit": 1,
    "gradient_accumulation_steps": 1,
    "output_dir": "sft_output/llama3/sft_pubmedqa",
    "logging_steps": 10,
    "num_train_epochs": 3,
    "max_seq_length": 3072,
    "max_steps": -1,
    "lr_scheduler_type": "cosine",
    "gradient_checkpointing": true,
    "use_peft": true,
    "lora_r": 256,
    "lora_alpha": 32
}